---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am Yusen Peng, a final year undergraduate Computer Science and Engineering (CSE) student at The Ohio State University (OSU), graduating in Spring 2026.

My research interest is primarily **multimodality** with a specific focus on **efficiency**. I like to tackle this problem from two orthogonal perspectives:
- *data sparsity* - token pruning, token merging
- *weight sparsity* - low-rank approximation (SVD), MoE

Ongoing Projects ‚≠êÔ∏è
======

<div style="display:flex;align-items:center;margin-bottom:30px;">
  <img src="../images/DRIP.png" alt="DRIP" style="width:350px;height:170px;margin-right:20px;">
  <div class="paper-info">
    <h3 style="margin-top:0;">Dynamic Patch Pooling for Efficient Vision Transformers</h3>
    <strong>Yusen Peng</strong>, Sachin Kumar<br>
    <a href="https://github.com/Yusen-Peng/DRIP" target="_blank">[Github]</a>
  </div>
</div>


Publications üöÄ
======

<div style="display:flex;align-items:center;margin-bottom:30px;">
  <img src="../images/CE-Bench.png" alt="CE-Bench" style="width:350px;height:180px;margin-right:20px;">
  <div class="paper-info">
    <h3 style="margin-top:0;">CE-Bench: Towards a Reliable Contrastive Evaluation Benchmark of Interpretability of Sparse Autoencoders</h3>
    Alex Gulko*, <strong>Yusen Peng*</strong>, Sachin Kumar.<br>
    <i>Proceedings of the 8th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP</i><br>
    <a href="https://arxiv.org/abs/2509.00691" target="_blank">[Arxiv]</a> | 
    <a href="https://aclanthology.org/2025.blackboxnlp-1.1" target="_blank">[ACL Anthology]</a> |
    <a href="https://github.com/Yusen-Peng/CE-Bench" target="_blank">[Github]</a> |
    <a href="https://huggingface.co/datasets/GulkoA/contrastive-stories-v4" target="_blank">[HuggingFace]</a>
  </div>
</div>

<div style="display:flex;align-items:center;margin-bottom:30px;">
  <img src="../images/CascadeFormer.png" alt="CascadeFormer" style="width:350px;height:160px;margin-right:20px;">
  <div class="paper-info">
    <h3 style="margin-top:0;">CascadeFormer: A Family of Two-stage Cascading Transformers for Skeleton-based Human Action Recognition</h3>
    <strong>Yusen Peng</strong>, Alper Yilmaz.<br>
    <i>arXiv preprint 2025; under review at ICPR</i><br>
    <a href="https://arxiv.org/abs/2509.00692" target="_blank">[Arxiv]</a> | 
    <a href="https://github.com/Yusen-Peng/CascadeFormer" target="_blank">[Github]</a> |
    <a href="https://huggingface.co/YusenPeng/CascadeFormerCheckpoints" target="_blank">[HuggingFace]</a> 
  </div>
</div>


<div style="display:flex;align-items:center;margin-bottom:30px;">
  <img src="../images/pytskit-architecture.png" alt="SIGNAL" style="width:400px;height:180px;margin-right:20px;">
  <div class="paper-info">
    <h3 style="margin-top:0;">pytskit: A Comprehensive Time Series Toolkit</h3>
    <!-- <strong>Yusen Peng</strong><br> -->
    Fan Yang, <strong>Yusen Peng</strong>, Tomasz Frelek, Frank Li, Qiao Xiao, Mark Kikta, John Paparrizos<br>
    <i>Under review at JMLR</i><br>
    <!-- <a href="" target="_blank">[paper (coming soon)]</a> |  -->
    [paper (coming soon)] | 
    <a href="https://github.com/thedatumorg/pytskit" target="_blank">[Github]</a>

  </div>
</div>

<div style="display:flex;align-items:center;margin-bottom:30px;">
  <img src="../images/SVD.png" alt="SVD-Pi3" style="width:350px;height:190px;margin-right:20px;">
  <div class="paper-info">
    <h3 style="margin-top:0;">Data-adaptive SVD for Efficient Visual Geometry Learning</h3>
    <strong>Yusen Peng</strong>, Haoxuan Wang, Yan Yan<br> 
    <i>preparing for ECCV 2026</i><br>

    <!-- <a href="" target="_blank">[paper (coming soon)]</a> |  -->
    [paper (coming soon)] | 
    <a href="https://github.com/Yusen-Peng/SVD-Pi3" target="_blank">[Github]</a>
  </div>
</div>

<div style="display:flex;align-items:center;margin-bottom:30px;">
  <img src="../images/public_housing.png" alt="public_housing" style="width:300px;height:120px;margin-right:20px;">
  <div class="paper-info">
    <h3 style="margin-top:0;">Lower-quality public housing corresponds to elevated flood risk and social disadvantage</h3>
    Woi Sok Oh, Kelsea Best, Meri Davlasheridze, <strong>Yusen Peng</strong><br>
    <i>Under review at Earth‚Äôs Future</i><br>
    <a href="https://docs.google.com/document/d/1xQ40GUl8wWLM5I9q8T6M7Y-kDxelpi6-lIUt2vzz3KQ/edit?usp=sharing" target="_blank">[Paper]</a>
  </div>
</div>


Undergraduate Thesis ‚úçÔ∏è
======

<div style="display:flex;align-items:center;margin-bottom:30px;">
  <img src="../images/CascadeFormer2.png" alt="SVD-Pi3" style="width:450px;height:170px;margin-right:20px;">
  <div class="paper-info">
    <h3 style="margin-top:0;">From Representation to Policy: Cascade Finetuning and Verifiable Reward Alignment for Human Action Understanding</h3>
    <strong>Yusen Peng</strong>, Alper Yilmaz<br> 
    <i>Undergraduate Thesis</i><br>
    <!-- <a href="" target="_blank">[paper (coming soon)]</a> |  -->
    [paper (coming after defense)]
    <!-- <a href="https://github.com/Yusen-Peng/CascadeFormer2" target="_blank">[Github]</a> -->
  </div>
</div>



Awards üèÖ
======

* **Honorable Mention, CRA Outstanding Undergraduate Researcher Award (2025)**
  * by Computing Research Association (CRA)

* **Undergraduate Research Scholarship 2025 @ OSU**
  * $2,200 scholarship awarded based on my Honors Thesis proposal @ OSU

Academic Service üìö
======

* **Conference Reviewer** @ NeurIPS
  * reviewed 3 papers at [NeurIPS 2025 Mechanistic Interpretability Workshop](https://mechinterpworkshop.com)

